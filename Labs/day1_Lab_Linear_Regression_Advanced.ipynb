{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxn9dN5ji2Sl"
   },
   "source": [
    "# Regression\n",
    "\n",
    "> In this notebook we will cover the preprocessing of a tabular data and will use following algorithms:\n",
    "\n",
    "> 1. Linear Regression\n",
    "> 2. Ridge Regression\n",
    "> 3. LASSO Regression\n",
    "> 4. Support Vector Machine\n",
    "> 5. Decision Tree Regressor\n",
    "> 6. Random Forest Regressor\n",
    "> 7. LightGBM\n",
    "> 8. CatBoost\n",
    "\n",
    "---\n",
    "\n",
    "# Data\n",
    "https://www.kaggle.com/datasets/vedavyasv/usa-housing\n",
    "> We are going to use the `USA_Housing` dataset. Since house price is a continuous variable, this is a regression problem. The data contains the following columns:\n",
    "\n",
    "> * '`Avg. Area Income`': Avg. The income of residents of the city house is located in.\n",
    "> * '`Avg. Area House Age`': Avg Age of Houses in the same city\n",
    "> * '`Avg. Area Number of Rooms`': Avg Number of Rooms for Houses in the same city\n",
    "> * '`Avg. Area Number of Bedrooms`': Avg Number of Bedrooms for Houses in the same city\n",
    "> * '`Area Population`': The population of city house is located in\n",
    "> * '`Price`': Price that the house sold at\n",
    "> * '`Address`': Address for the house\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xU9jJiy8i2Sm"
   },
   "source": [
    "#  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_23bFR8li_4Z"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install dask[dataframe] catboost\n",
    "\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:36:15.604668Z",
     "start_time": "2024-12-26T05:36:15.599055Z"
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:37:52.699134Z",
     "iopub.status.busy": "2024-12-25T20:37:52.698869Z",
     "iopub.status.idle": "2024-12-25T20:37:52.703803Z",
     "shell.execute_reply": "2024-12-25T20:37:52.702671Z",
     "shell.execute_reply.started": "2024-12-25T20:37:52.699116Z"
    },
    "id": "qZmZ7jZli2Sm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kagglehub\n",
    "import os\n",
    "import zipfile\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouYAXkQZi2Sn"
   },
   "source": [
    "##  Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:37:27.400474Z",
     "start_time": "2024-12-26T05:37:26.913736Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIXGZ6oki2Sn",
    "outputId": "69b4d002-99cd-4014-8237-23ce564660ea"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"aariyan101/usa-housingcsv\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:37:50.861825Z",
     "start_time": "2024-12-26T05:37:50.844429Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:37:53.445176Z",
     "iopub.status.busy": "2024-12-25T20:37:53.444898Z",
     "iopub.status.idle": "2024-12-25T20:37:53.466398Z",
     "shell.execute_reply": "2024-12-25T20:37:53.465423Z",
     "shell.execute_reply.started": "2024-12-25T20:37:53.445156Z"
    },
    "id": "pUuUlMXti2Sn",
    "outputId": "50e00d54-84fb-4422-ed3d-0131961079bc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "csv_path = os.path.join(path, \"USA_Housing.csv\")\n",
    "\n",
    "USAhousing = pd.read_csv(csv_path)\n",
    "USAhousing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:37:51.532126Z",
     "start_time": "2024-12-26T05:37:51.517904Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T15:22:49.575207Z",
     "iopub.status.busy": "2024-12-25T15:22:49.574862Z",
     "iopub.status.idle": "2024-12-25T15:22:49.600944Z",
     "shell.execute_reply": "2024-12-25T15:22:49.599894Z",
     "shell.execute_reply.started": "2024-12-25T15:22:49.575180Z"
    },
    "id": "l5SIzhrwi2So",
    "outputId": "0c179cb3-2f09-4b19-b949-28d8c52b1f74",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "USAhousing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:37:57.740693Z",
     "start_time": "2024-12-26T05:37:57.723330Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T15:22:53.316516Z",
     "iopub.status.busy": "2024-12-25T15:22:53.316158Z",
     "iopub.status.idle": "2024-12-25T15:22:53.344392Z",
     "shell.execute_reply": "2024-12-25T15:22:53.343174Z",
     "shell.execute_reply.started": "2024-12-25T15:22:53.316487Z"
    },
    "id": "PCEEHuHIi2So",
    "outputId": "3bfaf980-b037-4666-e22a-3fe32b23b76a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "USAhousing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pmd8B-B0i2So"
   },
   "source": [
    "# ðŸ“Š Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's create some simple plots to check out the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:38:15.896098Z",
     "start_time": "2024-12-26T05:38:09.222211Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T15:23:00.266007Z",
     "iopub.status.busy": "2024-12-25T15:23:00.265585Z",
     "iopub.status.idle": "2024-12-25T15:23:10.938165Z",
     "shell.execute_reply": "2024-12-25T15:23:10.936850Z",
     "shell.execute_reply.started": "2024-12-25T15:23:00.265976Z"
    },
    "id": "4N8p_BpCi2So",
    "outputId": "7ecf3485-58f6-4a83-df30-43081f1d6fed",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(USAhousing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTw10DU7i2So"
   },
   "source": [
    "> * Notice that the relationship between \"Price\" and \"Avg. Area Income\" shows a clear positive correlation: higher income tends to be associated with higher property prices.\n",
    "> * Also, the scatter plots between \"Avg. Area Number of Bedrooms\" and other variables show horizontal/vertical stripes, suggesting this variable is categorical or has fixed values (discrete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:38:40.787459Z",
     "start_time": "2024-12-26T05:38:40.519509Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T15:32:26.956795Z",
     "iopub.status.busy": "2024-12-25T15:32:26.956316Z",
     "iopub.status.idle": "2024-12-25T15:32:27.393326Z",
     "shell.execute_reply": "2024-12-25T15:32:27.392145Z",
     "shell.execute_reply.started": "2024-12-25T15:32:26.956734Z"
    },
    "id": "KW8SSIfJi2Sp",
    "outputId": "28e0c381-66da-459f-c98b-0c710e3ae45f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(USAhousing.drop(\"Address\",axis=1).corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcEnu_7Gi2Sp"
   },
   "source": [
    "#  Features Engineering\n",
    "\n",
    "> We have one text column in the data (i.e. Address). Maybe we can extract the town/city name from it and use it as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:38:57.799105Z",
     "start_time": "2024-12-26T05:38:57.776247Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:37:58.707495Z",
     "iopub.status.busy": "2024-12-25T20:37:58.707131Z",
     "iopub.status.idle": "2024-12-25T20:37:58.729811Z",
     "shell.execute_reply": "2024-12-25T20:37:58.729046Z",
     "shell.execute_reply.started": "2024-12-25T20:37:58.707470Z"
    },
    "id": "nJmrlqzGi2Sp",
    "outputId": "049e57f7-9fa0-47fd-ed0f-79d768748a64",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Extract city/town from the \"Address\" column (Not optimal, we just take the first word after the \\n. You can see many mistakes)\n",
    "USAhousing['City/Town'] = USAhousing['Address'].str.split('\\n').str[1].str.split(',').str[0]\n",
    "USAhousing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1P9nt-Xi2Sp"
   },
   "source": [
    "> Let's add some interaction features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:39:30.611768Z",
     "start_time": "2024-12-26T05:39:30.593552Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:37:59.624923Z",
     "iopub.status.busy": "2024-12-25T20:37:59.624635Z",
     "iopub.status.idle": "2024-12-25T20:37:59.643721Z",
     "shell.execute_reply": "2024-12-25T20:37:59.642326Z",
     "shell.execute_reply.started": "2024-12-25T20:37:59.624904Z"
    },
    "id": "0o1fW-azi2Sp",
    "outputId": "ca5959aa-9445-48b0-ef36-7cdca8812fba",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Wealthier areas with more rooms might be associated with higher property prices.\n",
    "USAhousing['Income_per_Room'] = USAhousing['Avg. Area Income'] / USAhousing['Avg. Area Number of Rooms']\n",
    "# Combine population and number of rooms to estimate density.\n",
    "USAhousing['Population_per_Room'] = USAhousing['Area Population'] / USAhousing['Avg. Area Number of Rooms']\n",
    "# Room-to-Bedroom Ratio: Might helps identify homes with better layouts.\n",
    "USAhousing['Room_to_Bedroom_Ratio'] = USAhousing['Avg. Area Number of Rooms'] / USAhousing['Avg. Area Number of Bedrooms']\n",
    "# Age-to-Income Ratio: Indicates older homes in wealthier areas.\n",
    "#############################\n",
    "#TODO, add \"Age_to_Income_Ratio\"\n",
    "\n",
    "\n",
    "#############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSngyfTKi2Sp"
   },
   "source": [
    "> * Aggregations are one of the most powerful feature engineering techniques, as they summarize group-level patterns\n",
    "> * E.g. average of income per city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:39:39.356292Z",
     "start_time": "2024-12-26T05:39:39.328753Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:38:02.919513Z",
     "iopub.status.busy": "2024-12-25T20:38:02.919219Z",
     "iopub.status.idle": "2024-12-25T20:38:02.944903Z",
     "shell.execute_reply": "2024-12-25T20:38:02.943694Z",
     "shell.execute_reply.started": "2024-12-25T20:38:02.919494Z"
    },
    "id": "e01Tlis0i2Sp",
    "outputId": "1ef9788a-45a7-4c26-dd44-0f5ed54aa34b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate average and median for selected columns for each City/Town\n",
    "city_aggregates = USAhousing.groupby('City/Town').agg({\n",
    "    'Avg. Area Income': ['mean', 'median'],\n",
    "    'Avg. Area House Age': ['mean', 'median'],\n",
    "    'Avg. Area Number of Rooms': ['mean', 'median'],\n",
    "    'Area Population': ['mean', 'median']\n",
    "})\n",
    "city_aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:39:52.254384Z",
     "start_time": "2024-12-26T05:39:52.231857Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:38:03.416016Z",
     "iopub.status.busy": "2024-12-25T20:38:03.415748Z",
     "iopub.status.idle": "2024-12-25T20:38:03.440790Z",
     "shell.execute_reply": "2024-12-25T20:38:03.439888Z",
     "shell.execute_reply.started": "2024-12-25T20:38:03.415997Z"
    },
    "id": "ST11FKkdi2Sq",
    "outputId": "1ec03ab6-4507-490c-8a14-52871496cf82",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Rename the columns for clarity\n",
    "city_aggregates.columns = ['Income_avg_per_city', 'Income_median_per_city',\n",
    "                           'HouseAge_avg_per_city', 'HouseAge_median_per_city',\n",
    "                           'Rooms_avg_per_city', 'Rooms_median_per_city',\n",
    "                           'Population_avg_per_city', 'Population_median_per_city']\n",
    "\n",
    "# Merge the aggregated data back into the original dataset\n",
    "USAhousing = USAhousing.merge(city_aggregates, on='City/Town', how='left')\n",
    "\n",
    "# Display the first few rows of the updated dataset\n",
    "USAhousing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pA3uqtopi2Sq"
   },
   "source": [
    "#  Data Preprocessing\n",
    "\n",
    "> Let's check the missing values.\n",
    ">\n",
    "> Also we don't need the Address, so will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:40:13.463300Z",
     "start_time": "2024-12-26T05:40:13.458910Z"
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:38:06.422343Z",
     "iopub.status.busy": "2024-12-25T20:38:06.422071Z",
     "iopub.status.idle": "2024-12-25T20:38:06.427360Z",
     "shell.execute_reply": "2024-12-25T20:38:06.426412Z",
     "shell.execute_reply.started": "2024-12-25T20:38:06.422324Z"
    },
    "id": "-5GX3xXWi2Sq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "USAhousing = USAhousing.drop(\"Address\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:40:16.006609Z",
     "start_time": "2024-12-26T05:40:15.999586Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:38:08.511353Z",
     "iopub.status.busy": "2024-12-25T20:38:08.511087Z",
     "iopub.status.idle": "2024-12-25T20:38:08.518316Z",
     "shell.execute_reply": "2024-12-25T20:38:08.517457Z",
     "shell.execute_reply.started": "2024-12-25T20:38:08.511335Z"
    },
    "id": "UVAzQ2mEi2Sq",
    "outputId": "3d6f1da3-1767-4f51-a7bf-7b7c0e9a1850",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "# TODO, report the missing values if any\n",
    "#missing_values = ??\n",
    "#############################\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSpT5L_wi2Sq"
   },
   "source": [
    "> The City/Town column is categorical. We should convert it to numerical before inputting it into the model.\n",
    "\n",
    "> We will use LabelEncoder from sklearn, which should give each category a unique number.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:40:33.224870Z",
     "start_time": "2024-12-26T05:40:33.128897Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:38:09.734850Z",
     "iopub.status.busy": "2024-12-25T20:38:09.734572Z",
     "iopub.status.idle": "2024-12-25T20:38:09.760162Z",
     "shell.execute_reply": "2024-12-25T20:38:09.759035Z",
     "shell.execute_reply.started": "2024-12-25T20:38:09.734830Z"
    },
    "id": "g3aR8J2Ei2Sq",
    "outputId": "3d14f800-aa7d-4810-cf5c-965858877268",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the City/Town column\n",
    "USAhousing['City/Town'] = label_encoder.fit_transform(USAhousing['City/Town'])\n",
    "USAhousing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXbFcXORi2Sq"
   },
   "source": [
    "> Linear models and SVM don't work well without scaling the values.\n",
    ">\n",
    "> We will use MinMaxScaler from sklearn, which would convert the values to range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:41:06.898947Z",
     "start_time": "2024-12-26T05:41:06.875237Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:38:12.093164Z",
     "iopub.status.busy": "2024-12-25T20:38:12.092836Z",
     "iopub.status.idle": "2024-12-25T20:38:12.120544Z",
     "shell.execute_reply": "2024-12-25T20:38:12.119669Z",
     "shell.execute_reply.started": "2024-12-25T20:38:12.093147Z"
    },
    "id": "eeLOvWpxi2Sq",
    "outputId": "f61d4bd9-2f68-446b-923b-eddfe11e6f7c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# We want to scale all the columns, BUT NOT THE TARGET\n",
    "cols = USAhousing.columns.drop(\"Price\") # Ask the students why?\n",
    "\n",
    "# Fit and transform the City/Town column\n",
    "USAhousing[cols] = scaler.fit_transform(USAhousing[cols])\n",
    "USAhousing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzgCXJlci2Sr"
   },
   "source": [
    "#  Training our Regression Models\n",
    "\n",
    "> We will need to first split up our data into an X array that contains the features to train on, and a y array with the target variable, in this case, the Price column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:41:21.460244Z",
     "start_time": "2024-12-26T05:41:21.454329Z"
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:38:14.609708Z",
     "iopub.status.busy": "2024-12-25T20:38:14.609400Z",
     "iopub.status.idle": "2024-12-25T20:38:14.614932Z",
     "shell.execute_reply": "2024-12-25T20:38:14.613657Z",
     "shell.execute_reply.started": "2024-12-25T20:38:14.609689Z"
    },
    "id": "BjCoRlHji2Sr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "# TODO,\n",
    "#X = ??\n",
    "#y = ??\n",
    "#############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlrD2G81i2Sr"
   },
   "source": [
    "> We will use KFold to evaluate our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:43:13.127902Z",
     "start_time": "2024-12-26T05:42:35.403051Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:57:57.344514Z",
     "iopub.status.busy": "2024-12-25T20:57:57.344231Z",
     "iopub.status.idle": "2024-12-25T20:58:31.051641Z",
     "shell.execute_reply": "2024-12-25T20:58:31.050361Z",
     "shell.execute_reply.started": "2024-12-25T20:57:57.344497Z"
    },
    "id": "uyp7PsJii2Sr",
    "outputId": "62a19366-cae6-42e8-be5f-116471cc987e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=10, positive=True, max_iter=10000),\n",
    "    \"LASSO Regression\": Lasso(alpha=100, positive=True, max_iter=10000),\n",
    "    \"Support Vector Machine\": SVR(kernel='linear'),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(max_depth=5),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100),\n",
    "    \"LightGBM\": LGBMRegressor(verbose=-1),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0)\n",
    "}\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    scores_mae = []\n",
    "    scores_rmse = []\n",
    "\n",
    "    # 5-Fold cross-validation\n",
    "    for train_index, test_index in KFold(n_splits=5).split(X, y):\n",
    "        # Split data into training and testing sets\n",
    "        X_Train, X_Test = X.loc[train_index,:], X.loc[test_index,:]\n",
    "        y_Train, y_Test = y[train_index], y[test_index]\n",
    "        # Train the model\n",
    "        model.fit(X_Train, y_Train)\n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_Test)\n",
    "        # Calculate metrics\n",
    "        scores_mae.append(mean_absolute_error(y_Test, y_pred))\n",
    "        scores_rmse.append(np.sqrt(mean_squared_error(y_Test, y_pred)))\n",
    "    # Print the results\n",
    "    print(f\"{model_name} MAE Score: {np.mean(scores_mae)}\")\n",
    "    print(f\"{model_name} RMSE Score: {np.mean(scores_rmse)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kyD79xvi2Sr"
   },
   "source": [
    "> * is RMSE=100k good? How to know if a score is good or not?\n",
    ">\n",
    "> * We need something to compare against. We need a **Baseline**.\n",
    ">\n",
    "> * If our models are better than the baseline score, then they are good.\n",
    ">\n",
    "> * The simplest baseline we can consider is the mean of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:43:54.209141Z",
     "start_time": "2024-12-26T05:43:54.201303Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T21:19:37.942212Z",
     "iopub.status.busy": "2024-12-25T21:19:37.941908Z",
     "iopub.status.idle": "2024-12-25T21:19:37.948900Z",
     "shell.execute_reply": "2024-12-25T21:19:37.948040Z",
     "shell.execute_reply.started": "2024-12-25T21:19:37.942192Z"
    },
    "id": "3--GjzdDi2Sr",
    "outputId": "87c7d93c-9125-4004-d273-959fc45c5496",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate the baseline predictions (mean of the target)\n",
    "baseline_pred = np.full_like(y, y.mean())\n",
    "\n",
    "# Evaluate the baseline\n",
    "#############################\n",
    "# TODO, find the baseline error\n",
    "#baseline_mae = ??\n",
    "#############################\n",
    "baseline_sqrt = np.sqrt(mean_squared_error(y, baseline_pred))\n",
    "\n",
    "print(f\"Baseline MAE (using mean target): {baseline_mae:.4f}\")\n",
    "print(f\"Baseline RMSE (using mean target): {baseline_sqrt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnDWWyN3i2Sr"
   },
   "source": [
    "> * Yeah our models are significanlty better than the baselines (Except the SVM).\n",
    ">\n",
    "> * Let's Check what are the important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:44:39.004936Z",
     "start_time": "2024-12-26T05:44:38.779246Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:52:28.997055Z",
     "iopub.status.busy": "2024-12-25T20:52:28.996766Z",
     "iopub.status.idle": "2024-12-25T20:52:29.246533Z",
     "shell.execute_reply": "2024-12-25T20:52:29.245488Z",
     "shell.execute_reply.started": "2024-12-25T20:52:28.997031Z"
    },
    "id": "IDQsOyt7i2Sr",
    "outputId": "ddfe3ebb-bb9d-4e24-aef7-4659cc9ce280",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Retrieve Ridge coefficients and sort by absolute importance\n",
    "ridge_model = models[\"Ridge Regression\"]\n",
    "ridge_importance = list(zip(X.columns, ridge_model.coef_))\n",
    "sorted_ridge_importance = sorted(ridge_importance, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Extract sorted features and their coefficients\n",
    "features, coefficients = zip(*sorted_ridge_importance)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, coefficients, color='darkblue')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Ridge Regression Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show the most important features at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:45:11.516978Z",
     "start_time": "2024-12-26T05:45:11.287267Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:52:29.248219Z",
     "iopub.status.busy": "2024-12-25T20:52:29.247901Z",
     "iopub.status.idle": "2024-12-25T20:52:29.474307Z",
     "shell.execute_reply": "2024-12-25T20:52:29.473248Z",
     "shell.execute_reply.started": "2024-12-25T20:52:29.248198Z"
    },
    "id": "osu8Gawmi2Ss",
    "outputId": "0f963d45-570a-4bb0-ac36-8e8dd4ce82ba",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Retrieve LASSO coefficients and sort by absolute importance\n",
    "lasso_model = models[\"LASSO Regression\"]\n",
    "lasso_importance = list(zip(X.columns, lasso_model.coef_))\n",
    "sorted_lasso_importance = sorted(lasso_importance, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Extract features and their coefficients\n",
    "features, coefficients = zip(*sorted_lasso_importance)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, coefficients, color='darkred')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Features')\n",
    "plt.title('LASSO Regression Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show the most important features at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "va6xtfv_i2Ss"
   },
   "source": [
    "### Notice how Lasso zeroed most of the features and just focused on the most important features.\n",
    "### This is what we call \"sparse weights\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T05:46:09.556835Z",
     "start_time": "2024-12-26T05:46:09.344533Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T20:52:56.280222Z",
     "iopub.status.busy": "2024-12-25T20:52:56.279930Z",
     "iopub.status.idle": "2024-12-25T20:52:56.534220Z",
     "shell.execute_reply": "2024-12-25T20:52:56.533294Z",
     "shell.execute_reply.started": "2024-12-25T20:52:56.280202Z"
    },
    "id": "L9CNCSe_i2Ss",
    "outputId": "4275d1f8-8dbf-41a0-bf2e-99fbf589ce55",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Retrieve CatBoost feature importances and sort them\n",
    "catboost_model = models[\"CatBoost\"]\n",
    "catboost_importance = list(zip(X.columns, catboost_model.feature_importances_))\n",
    "sorted_catboost_importance = sorted(catboost_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract features and their importances\n",
    "features, importances = zip(*sorted_catboost_importance)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, importances, color='orange')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title('CatBoost Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show the most important features at the top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLROzR4ni2Ss"
   },
   "source": [
    "## Final Notes:\n",
    "> * Gradient Boosting algorithms (e.g., LightGBM, CatBoost) often outperform other algorithms in tabular data. However, in this case, linear models outperformed others, suggesting a strong linear relationship between the features and the target.\n",
    "\n",
    "\n",
    "> * Notice how LASSO eliminated many of the engineered features, indicating they might not contribute significantly to predictive performance.\n",
    "\n",
    "\n",
    "> * Remember, feature engineering is an iterative process. You add new features, evaluate their impact using cross-validation (CV), and refine based on the results. What we did here is just adding features based on our intution and run the model. But it is possible that all of them are useless **(Try to rerun the notebook without the feature engineering part and check if scores improve)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgZEMGr0i2Ss"
   },
   "source": [
    "# Created by:\n",
    "[Mohamed Eltayeb](https://www.kaggle.com/mohammad2012191)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    },
    {
     "datasetId": 4909,
     "sourceId": 7459,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
