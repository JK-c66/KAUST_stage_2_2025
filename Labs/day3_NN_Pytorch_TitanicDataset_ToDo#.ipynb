{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "CugS7fzDzJ4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9sfSnJ6XzMzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***useful information for predicting survival (the target variable)***"
      ],
      "metadata": {
        "id": "s2kFOVWzMpSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "mVqpR88gzPPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')"
      ],
      "metadata": {
        "id": "LbA4EpajzRlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display and Explore the dataset**"
      ],
      "metadata": {
        "id": "dE0jHdIYzWCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "9kOXrzpMN1AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "XBm3uHCh0vQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe"
      ],
      "metadata": {
        "id": "1U_jaSz40xu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "Gnm0GXYyzZXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo: Check Null Value\n",
        "null_values = data[data['Age'].???]\n",
        "print(null_values)"
      ],
      "metadata": {
        "id": "Hzyl61egNVBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "F6whR8r9zao9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Dropping unnecessary columns\n",
        "data = data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "## Handling missing values\n",
        "\n",
        "# Todo: Fill the Null Values with one of this (mean, median, mode, ...)\n",
        "data['Age'].???(data['Age'].???(), inplace=True) # The median is used instead of the mean because it is less sensitive to outliers, and it helps to maintain the distribution of the data. The inplace=True argument modifies the DataFrame in place.\n",
        "data['Embarked'].???(data['Embarked'].mode()[0], inplace=True) # This fills the missing values in the 'Embarked' column with the most frequent value (mode).\n",
        "\n",
        "## Encoding categorical features\n",
        "# Todo: Create a Label Encoder and Fit the data\n",
        "le = ??? # convert categorical variables into numerical format (require in decision trees or neural networks).\n",
        "data['Sex'] = le.???(data['Sex']) # 0 represents 'male', and 1 represents 'female'\n",
        "data['Embarked'] = le.???(data['Embarked'])\n",
        "\n",
        "## Splitting features and target\n",
        "\n",
        "# Todo: Split the Feature and the target\n",
        "X = ??? # X represents the input variables (features) for the model. 'Survived' is excluded because itâ€™s the target variable (what the model needs to predict)\n",
        "y = ??? # y will be the output of the model, the variable we want to predict.\n",
        "\n",
        "## Standardizing the data\n",
        "scaler = StandardScaler() # standardize the features by removing the mean and scaling to unit variance\n",
        "X = scaler.fit_transform(X) # It computes the mean and standard deviation of each feature and then scales each feature to have a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "## Splitting into training and testing sets\n",
        "\n",
        "# Todo: Split the Data, 0.20 for testing and 0.80 for training\n",
        "X_train, X_test, y_train, y_test = ???(???, ???, ???, random_state=42)\n",
        "\n",
        "## Converting data to PyTorch tensors\n",
        "# PyTorch tensors, which are the data structure used in PyTorch for efficient computation on the GPU\n",
        "# Todo: Convert to Tensor\n",
        "X_train_tensor = ???(X_train, dtype=torch.float32)\n",
        "X_test_tensor = ???(X_test, dtype=torch.float32)\n",
        "\n",
        "# .values converts the pandas Series into a numpy array (since PyTorch does not work directly with pandas Series).\n",
        "# .unsqueeze(1) adds an additional dimension, which is necessary because the model expects targets to be in a 2D format (for binary classification, it expects a column vector).\n",
        "# Todo: unsqueeze the Data to be a 2D Format\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).???\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).???"
      ],
      "metadata": {
        "id": "5w540956zd4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "KApzpdNnzgXd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4E5D7qQxpHE"
      },
      "outputs": [],
      "source": [
        "class TitanicModel(nn.Module):\n",
        "    def __init__(self):\n",
        "      # Todo: Compleate the Paramaters and add Activation Function\n",
        "        super(TitanicModel, self).__init__()\n",
        "        self.layer_1 = nn.Linear(X_train.shape[1], 16) # IL\n",
        "        self.layer_2 = nn.Linear(???, ???) # HL\n",
        "        self.output = nn.Linear(???, ???) # OL\n",
        "        self.??? = nn.???() # AF\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Todo: Compleate the Non Linearity for all Layers\n",
        "        x = torch.???(self.layer_1(???)) # add non-linearity\n",
        "        x = torch.???(self.layer_2(???))\n",
        "        x = self.sigmoid(self.output(x)) # map the output between 0 and 1, which is needed for binary classification\n",
        "        return x\n",
        "\n",
        "class TitanicModelVariant1(nn.Module):\n",
        "    def __init__(self):\n",
        "      # Todo: Compleate the Paramaters and add Activation Function\n",
        "        super(TitanicModelVariant1, self).__init__()\n",
        "        self.layer_1 = nn.Linear(X_train.shape[1], ???)\n",
        "        self.layer_2 = nn.Linear(32, ???)\n",
        "        self.layer_3 = nn.Linear(16, ???)\n",
        "        self.output = nn.Linear(8, ???)\n",
        "        self.??? = nn.???()\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Todo: Create Forward Function\n",
        "        x = ???\n",
        "        x = ???\n",
        "        x = ???\n",
        "        x = self.???(self.output(???))\n",
        "        return ???\n",
        "\n",
        "class TitanicModelVariant2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TitanicModelVariant2, self).__init__()\n",
        "        self.layer_1 = nn.Linear(X_train.shape[1], 16)\n",
        "        # Todo:\n",
        "        ???\n",
        "        ???\n",
        "        ???\n",
        "        ???\n",
        "        ???\n",
        "    def forward(self, x):\n",
        "        ???\n",
        "        ???\n",
        "        ???\n",
        "        ???\n",
        "        return ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Models, Loss Function, and Optimizer"
      ],
      "metadata": {
        "id": "dcX1Hn8szt_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Initialization\n",
        "# Todo: Initialize the all Model\n",
        "model = ???() # instance of the TitanicModel class (a simple 2-layer model)\n",
        "model_variant1 = ???() # instance of the TitanicModelVariant1 class (a 3-layer model with larger first hidden layer).\n",
        "model_variant2 = ???() # instance of the TitanicModelVariant2 class (a 3-layer model where the second hidden layer has the same number of units as the first).\n",
        "\n",
        "## Loss Function\n",
        "# BCELoss measures the difference between the predicted probability (between 0 and 1) and the actual target (either 0 or 1). The goal is to minimize this loss during training, helping the model make accurate predictions.\n",
        "# Todo: add the Loss\n",
        "criterion = nn.???() # Binary Cross Entropy Loss\n",
        "# Todo: add Optimizer\n",
        "optimizer = ???(model.parameters(), lr=0.001)\n",
        "optimizer_variant1 = ???(model_variant1.parameters(), lr=0.001)\n",
        "optimizer_variant2 = ???(model_variant2.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "qKneSPf1zyYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Function"
      ],
      "metadata": {
        "id": "3PWZ3ogDzyyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define number of epochs\n",
        "epochs = 100\n",
        "\n",
        "def train_model(model, optimizer, epochs):\n",
        "    #  Metrics Initialization\n",
        "    losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      # Todo: Train the Model\n",
        "        ???\n",
        "\n",
        "        # Forward pass for training data\n",
        "        y_pred_train = model(X_train_tensor)\n",
        "        # Todo: create a BCELoss for y pred and y train\n",
        "        train_loss = criterion(???, ???) # criterion (Binary Cross-Entropy Loss in this case)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        # Todo:\n",
        "        optimizer.???() # Clears the gradients from the previous step\n",
        "        train_loss.???() # Computes the gradient of the loss with respect parameters\n",
        "        optimizer.???() # Updates the model parameters using the computed gradients\n",
        "\n",
        "        # Todo: append the loss\n",
        "        losses.???(train_loss.???)\n",
        "\n",
        "    # Evaluate on test data\n",
        "    # Todo: chane model to evaluation mode\n",
        "        model.???() # Sets the model to evaluation mode, disabling certain features like dropout.\n",
        "        with torch.???(): # no gradients are calculate\n",
        "            # Todo: Train the Data and Calcualte the Loss\n",
        "            y_pred_test = model(???)\n",
        "            test_loss = criterion(???, ???).item() # criterion (Binary Cross-Entropy Loss in this case)\n",
        "            test_losses.append(test_loss)\n",
        "\n",
        "            # Calculate accuracies for training\n",
        "            # Todo: round the probabilities or use threshhold\n",
        "            y_pred_train_binary = (?? > 0.5).float() # Converts the predicted probabilities into binary predictions (0 or 1) using a threshold of 0.5.\n",
        "            train_accuracy = (y_pred_train_binary.eq(y_train_tensor).sum() / y_train_tensor.shape[0]).item()\n",
        "            train_accuracies.append(train_accuracy * 100)\n",
        "           # Calculate accuracies for testing\n",
        "            y_pred_test_binary = (y_pred_test > 0.5).float()\n",
        "            test_accuracy = (y_pred_test_binary.eq(y_test_tensor).sum() / y_test_tensor.shape[0]).item()\n",
        "            test_accuracies.append(test_accuracy * 100)\n",
        "\n",
        "        # Print loss every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss.item():.4f}, Test Loss: {test_loss:.4f}, \"\n",
        "                  f\"Train Accuracy: {train_accuracy * 100:.2f}%, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "    return losses, test_losses, train_accuracies, test_accuracies"
      ],
      "metadata": {
        "id": "sBu7ijFqz27j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train all models"
      ],
      "metadata": {
        "id": "kPPL2FL80BUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Default Model\")\n",
        "losses, test_losses, train_accuracies, test_accuracies = train_model(model, optimizer, epochs)\n",
        "\n",
        "print(\"\\nTraining Variant 1 Model\")\n",
        "losses_variant1, test_losses_variant1, train_accuracies_variant1, test_accuracies_variant1 = train_model(model_variant1, optimizer_variant1, epochs)\n",
        "\n",
        "print(\"\\nTraining Variant 2 Model\")\n",
        "losses_variant2, test_losses_variant2, train_accuracies_variant2, test_accuracies_variant2 = train_model(model_variant2, optimizer_variant2, epochs)"
      ],
      "metadata": {
        "id": "iV_XUDjr0D3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "smLV9E8z0FI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting the loss curves for all models**"
      ],
      "metadata": {
        "id": "5yifuTH20HlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(epochs), losses, label='Default Model Train Loss', color='blue')\n",
        "plt.plot(range(epochs), test_losses, label='Default Model Test Loss', color='orange')\n",
        "plt.plot(range(epochs), losses_variant1, label='Variant 1 Train Loss', color='green')\n",
        "plt.plot(range(epochs), test_losses_variant1, label='Variant 1 Test Loss', color='red')\n",
        "plt.plot(range(epochs), losses_variant2, label='Variant 2 Train Loss', color='purple')\n",
        "plt.plot(range(epochs), test_losses_variant2, label='Variant 2 Test Loss', color='brown')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Test Loss for Different Models')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vdcg34hsyDg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting accuracy curves for all models**"
      ],
      "metadata": {
        "id": "Ki4-e5P40Pww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(epochs), train_accuracies, label='Default Model Train Accuracy', color='blue')\n",
        "plt.plot(range(epochs), test_accuracies, label='Default Model Test Accuracy', color='orange')\n",
        "plt.plot(range(epochs), train_accuracies_variant1, label='Variant 1 Train Accuracy', color='green')\n",
        "plt.plot(range(epochs), test_accuracies_variant1, label='Variant 1 Test Accuracy', color='red')\n",
        "plt.plot(range(epochs), train_accuracies_variant2, label='Variant 2 Train Accuracy', color='purple')\n",
        "plt.plot(range(epochs), test_accuracies_variant2, label='Variant 2 Test Accuracy', color='brown')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Train vs Test Accuracy for Different Models')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8BTRBm_W0S1r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}